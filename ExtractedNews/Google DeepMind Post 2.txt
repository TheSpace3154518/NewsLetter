https://deepmind.google/discover/blog/
— Identifying AI-generated content
AlphaFold
          
          
          




 — Accelerating breakthroughs in biology with AI
Picture describing Diagram depicting the stages of a cyberattack chain, with icons and symbols representing each stage
Empowering the cybersecurity community
— Our mission is to build AI responsibly to benefit humanity
View Technologies
          
          
          
        

 — Solving the world’s most complex challenges
for evaluating the emerging offensive cyber capabilities of AI
— Our highest quality text-to-image model
We also found that existing AI cybersecurity evaluations often overlook major aspects of cyberattacks—such as evasion, where attackers hide their presence, and persistence, where they maintain long-term access to a compromised system. Yet such areas are precisely where AI-powered approaches can be particularly effective. Our framework shines a light on this issue by discussing how AI may lower the barriers to success in these parts of an attack.
— Our state-of-the-art video generation model
Blog
          
          
          
        

 — Discover our latest AI breakthroughs, projects, and updates
Genie 2: A large-scale foundation world model
Education
          
          
          
        

 — Our vision is to help make the AI ecosystem more representative of society
But to harness such benefits, we must also understand and mitigate the risks of increasingly advanced AI being misused to enable or enhance cyberattacks. Our new framework for evaluating the emerging offensive cyber capabilities of AI helps us do exactly this. It’s the most comprehensive evaluation of its kind to date: it covers every phase of the cyberattack chain, addresses a wide range of threat types, and is grounded in real-world data.
Breakthroughs
          
          
          
        

 — Explore some of the biggest innovations in AI
Gemini Robotics brings AI into the physical world
12 March 2025
— We want AI to benefit the world, so we must be thoughtful about how it’s built and used
Gemini 2.5: Our most intelligent AI model
25 March 2025
Our updated Frontier Safety Framework recognizes that advanced AI models could automate and accelerate cyberattacks, potentially lowering costs for attackers. This, in turn, raises the risks of attacks being carried out at greater scale.
Our initial evaluations using this benchmark suggest that in isolation, present-day AI models are unlikely to enable breakthrough capabilities for threat actors. However, as frontier AI becomes more advanced, the types of cyberattacks possible will evolve, requiring ongoing improvements in defense strategies.
Google DeepMind at NeurIPS 2024
5 December 2024
— Our vision is to help make the AI ecosystem more representative of society
— Many disciplines, one common goal
— A universal AI agent that is helpful in everyday life
Artificial intelligence (AI) has long been a cornerstone of cybersecurity. From malware detection to network traffic analysis, predictive machine learning models and other narrow AI applications have been used in cybersecurity for decades. As we move closer to artificial general intelligence (AGI), AI's potential to automate defenses and fix vulnerabilities becomes even more powerful.
SynthID
          
          
          
        

 — Identifying AI-generated content
The stages of a cyberattack chain
Veo 2
          
            
(New)
— Discover our latest breakthroughs and see how we’re shaping the future
Finally, we created an offensive cyber capability benchmark to comprehensively assess the cybersecurity strengths and weaknesses of frontier AI models. Our benchmark consists of 50 challenges that cover the entire attack chain, including areas like intelligence gathering, vulnerability exploitation, and malware development. Our aim is to provide defenders with the ability to develop targeted mitigations and simulate AI-powered attacks as part of red teaming exercises.
Imagen
          
          
          
        

 — Our highest quality text-to-image model
We’re exploring the frontiers of AGI, prioritizing technical safety, proactive risk assessment, and collaboration with the AI community.
Evaluating potential cybersecurity threats of advanced AI
2 April 2025
To stay ahead of the emerging threat of AI-powered cyberattacks, we’ve adapted tried-and-tested cybersecurity evaluation frameworks, such as MITRE ATT&CK. These frameworks enabled us to evaluate threats across the end-to-end cyber attack chain, from reconnaissance to action on objectives, and across a range of possible attack scenarios. However, these established frameworks were not designed to account for attackers using AI to breach a system. Our approach closes this gap by proactively identifying where AI could make attacks faster, cheaper, or easier—for instance, by enabling fully automated cyberattacks.
AlphaFold
          
          
          
        

 — Accelerating breakthroughs in biology with AI
Responsibility & Safety
Taking a responsible path to AGI
We’re exploring the frontiers of AGI, prioritizing technical safety, proactive risk assessment, and collaboration with the AI community.


2 April 2025
As AI systems continue to scale, their ability to automate and enhance cybersecurity has the potential to transform how defenders anticipate and respond to threats.
Publications
          
          
          
        

 — Explore a selection of our recent research
— Meet our team and learn more about our research
The Podcast
          
          
          
        

 — Uncover the extraordinary ways AI is transforming our world
Evaluating potential cybersecurity threats of advanced AI
— The most general and capable AI models we've ever built
— Explore some of the biggest innovations in AI
Our cybersecurity evaluation framework is designed to support that shift by offering a clear view of how AI might also be misused, and where existing cyber protections may fall short. By highlighting these emerging risks, this framework and benchmark will help cybersecurity teams strengthen their defenses and stay ahead of fast-evolving threats.
View Research
          
          
          
        

 — We work on some of the most complex and interesting challenges in AI.
— We work on some of the most complex and interesting challenges in AI.
Veo
          
          
          




 — Our state-of-the-art video generation model
Sign up for updates on our latest innovations
Learn about Google DeepMind
          
          
          
        

 — Our mission is to build AI responsibly to benefit humanity
— Explore a selection of our recent research
View Discover
          
          
          
        

 — Discover our latest breakthroughs and see how we’re shaping the future
— Uncover the extraordinary ways AI is transforming our world
Taking a responsible path to AGI
Gemini
          
          
          
        

 — The most general and capable AI models we've ever built
I accept Google's Terms and Conditions and acknowledge that my information will be used in accordance with Google's Privacy Policy.
Picture describing Featuring a sequence of transparent glass blocks, refracting hues of purple, blue and cyan, representing the frameworks which enable us to evaluate threats across the end-to-end cyber attack chain.
Careers
          
          
          
        

 — Many disciplines, one common goal
We analyzed over 12,000 real-world attempts to use AI in cyberattacks in 20 countries, drawing on data from Google’s Threat Intelligence Group. This helped us identify common patterns in how these attacks unfold. From these, we curated a list of seven archetypal attack categories—including phishing, malware, and denial-of-service attacks—and identified critical bottleneck stages along the cyberattack chain where AI could significantly disrupt the traditional costs of an attack. By focusing evaluations on these bottlenecks, defenders can prioritize their security resources more effectively.
Veo
          
          
          
        

 — Our state-of-the-art video generation model
— Accelerating breakthroughs in biology with AI
Building a comprehensive benchmark
— Solving the world’s most complex challenges
Project Astra
          
          
          
        

 — A universal AI agent that is helpful in everyday life
— Discover our latest AI breakthroughs, projects, and updates
Google’s Threat Intelligence Group
Responsibility & Safety
          
          
          
        

 — We want AI to benefit the world, so we must be thoughtful about how it’s built and used
Genie 2: A large-scale foundation world model
4 December 2024
Gemini Robotics brings AI into the physical world
Our framework enables cybersecurity experts to identify which defenses are necessary—and how to prioritize them—before malicious actors can exploit AI to carry out sophisticated cyberattacks.
Gemini 2.5: Our most intelligent AI model
Events
          
          
          
        

 — Meet our team and learn more about our research
Taking a responsible path to AGI
2 April 2025